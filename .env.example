# AI Server Configuration
# Copy this file to .env and fill in your values

# Model Configuration
MODEL_NAME=granite3-dense:2b
MODEL_PROVIDER=ollama

# LLM Server Configuration (Ollama)
# Set to empty or "none" to use OpenAI defaults
LLM_BASE_URL=http://localhost:11434
BASE_URL=http://localhost:11434

# Model Parameters
MODEL_TEMPERATURE=0.5
MODEL_NUM_CTX=8192

# Embeddings Configuration
EMBEDDINGS_MODEL=nomic-embed-text

# WebSearch Configuration
SEARX_HOST=http://localhost:8080
SEARCH_K=8
SEARX_TIMEOUT_S=8.0
SEARCH_LANG=en-US
SEARCH_SAFESEARCH=1

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# ChatAgent Configuration
CHAT_MESSAGES_TO_KEEP=5
CHAT_MAX_TOKENS_BEFORE_SUMMARY=4000
CHAT_MODEL_NAME=granite3-dense:2b

# WebSearch Agent Configuration  
WEBSEARCH_MODEL_NAME=llama3.1
WEBSEARCH_MAX_CATEGORIES=3
